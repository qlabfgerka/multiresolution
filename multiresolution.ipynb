{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchinfo\n",
    "import skimage\n",
    "\n",
    "TRAIN_FOLDER = 'train/'\n",
    "TEST_FOLDER = 'test/'\n",
    "\n",
    "EPOCHS = 10\n",
    "#BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutliresolution(torch.nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.first_conv2d = torch.nn.Conv2d(1, 64, kernel_size=(9, 9), padding=\"same\")\n",
    "    self.second_conv2d = torch.nn.Conv2d(64, 32, kernel_size=(5, 5), padding=\"same\")\n",
    "    self.third_conv2d = torch.nn.Conv2d(32, 1, kernel_size=(5, 5), padding=\"same\")\n",
    "    self.relu = torch.nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.first_conv2d(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.second_conv2d(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.third_conv2d(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image():\n",
    "    print(\"prepare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_image(image):\n",
    "  image[image > 1] = 1\n",
    "  image[image < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(image): \n",
    "  image = image / 255\n",
    "  fix_image(image)\n",
    "\n",
    "  image = image.astype(np.float32)\n",
    "  \n",
    "  expanded = image.transpose(-1, 0, 1)\n",
    "  expanded = np.expand_dims(expanded, axis = 0)\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "  images = []\n",
    "  for filename in os.listdir(folder):\n",
    "    image = cv2.imread(os.path.join(folder, filename), -1)\n",
    "    if image is not None:\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      images.append(image)\n",
    "\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_filters(filters, title):\n",
    "  # [N, C, H, W] -> [N, H, W, C]\n",
    "  filters = filters.permute(0, 2, 3, 1)\n",
    "  filters = filters.clamp(0, 1)\n",
    "\n",
    "  # Sortiraj po padajoči varianci\n",
    "  indices = torch.argsort(torch.var(filters, axis=(1, 2, 3)), descending=True)\n",
    "  filters = filters[indices]\n",
    "  _, axes = plt.subplots(4, 16, figsize=(16, 4))\n",
    "\n",
    "  for r in range(axes.shape[0]):\n",
    "    for c in range(axes.shape[1]):\n",
    "      if r == 0 and c == 0:\n",
    "          axes[r, c].set_title(title)\n",
    "      axes[r, c].imshow(filters[r * axes.shape[1] + c], cmap=\"gray\")\n",
    "      axes[r, c].axis(\"off\")\n",
    "      \n",
    "  plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, num, f1, f2, title = \"\"):\n",
    "    indices = np.random.default_rng().choice(len(images), num, replace=False)\n",
    "    _, axes = plt.subplots(f1, f2, figsize=(8, 3), squeeze=False) \n",
    "    \n",
    "    for r in range(axes.shape[0]):\n",
    "        for c in range(axes.shape[1]):\n",
    "            if r == 0 and c == 0:\n",
    "                axes[r, c].set_title(title)\n",
    "            axes[r, c].imshow(images[indices[r * axes.shape[1] + c]])\n",
    "            axes[r, c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_info(images, title, num, f1, f2):\n",
    "    heights = list(map(lambda image: image.shape[0], images))\n",
    "    widths = list(map(lambda image: image.shape[1], images))\n",
    "\n",
    "    print(f\"Število slik: {len(images)}\")\n",
    "    print(f\"Interval širine slik: [{np.min(widths)}, {np.max(widths)}]\") \n",
    "    print(f\"Interval višine slik: [{np.min(heights)}, {np.max(heights)}]\") \n",
    "    print(f\"Povprečna širina slik: {np.mean(widths) :.2f} +- {np.std(widths) :.2f}\") \n",
    "    print(f\"Povprečna višina slik: {np.mean(heights) :.2f} +- {np.std(heights) :.2f}\") \n",
    "    print(\"Primeri slik:\")\n",
    "    display_images(images, num, f1, f2, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images, factor, type):\n",
    "    low_res = []\n",
    "    high_res = []\n",
    "    originals = []\n",
    "\n",
    "    for image in images:\n",
    "        smaller_size = (int(image.shape[1] / factor), int(image.shape[0] / factor))\n",
    "        bigger_size = (int(smaller_size[0] * factor), int(smaller_size[1] * factor))\n",
    "        low_res_image = cv2.resize(image, smaller_size, cv2.INTER_LINEAR)\n",
    "        high_res_image = cv2.resize(low_res_image, bigger_size, cv2.INTER_LINEAR)\n",
    "\n",
    "        low_res_image = cv2.cvtColor(low_res_image, cv2.COLOR_BGR2YCR_CB)\n",
    "        high_res_image = cv2.cvtColor(high_res_image, cv2.COLOR_BGR2YCR_CB)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2YCR_CB)\n",
    "\n",
    "        if type == 0:\n",
    "            low_res_image = cv2.copyMakeBorder(low_res_image, 0, 33, 0, 33, cv2.BORDER_CONSTANT, None, value = 0)\n",
    "            high_res_image = cv2.copyMakeBorder(high_res_image, 0, 33, 0, 33, cv2.BORDER_CONSTANT, None, value = 0)\n",
    "            image = cv2.copyMakeBorder(image, 0, 33, 0, 33, cv2.BORDER_CONSTANT, None, value = 0)\n",
    "            \n",
    "            for i in range(0, smaller_size[0], 14):\n",
    "                for j in range(0, smaller_size[1], 14):\n",
    "                    low_res.append(low_res_image[j:j+33, i:i+33, 0:1])\n",
    "\n",
    "            for i in range(0, bigger_size[0], 14):\n",
    "                for j in range(0, bigger_size[1], 14):\n",
    "                    high_res.append(high_res_image[j:j+33, i:i+33, 0:1])\n",
    "\n",
    "            for i in range(0, bigger_size[0], 14):\n",
    "                for j in range(0, bigger_size[1], 14):\n",
    "                    originals.append(image[j:j+33, i:i+33, 0:1])\n",
    "        else:\n",
    "            low_res.append(low_res_image[:,:,0:1])\n",
    "            high_res.append(high_res_image[:,:,0:1])\n",
    "            originals.append(image[:,:,0:1])\n",
    "\n",
    "    display_dataset_info(low_res, \"LOW RESOLUTION IMAGES, FACTOR: \" + str(factor), 5, 1, 5)\n",
    "    display_dataset_info(high_res, \"HIGH RESOLUTION IMAGES, FACTOR: \" + str(factor), 5, 1, 5)\n",
    "    display_dataset_info(originals, \"ORIGINAL IMAGES, FACTOR: \" + str(factor), 5, 1, 5)\n",
    "    return low_res, high_res, originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(originals, low_res, epochs, factor):\n",
    "  model = Mutliresolution()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "  loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "  #dataset = torch.utils.data.TensorDataset(high_res, originals)\n",
    "  #dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "  model = model.to(device)\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    print('epoch:' + str(epoch + 1) + ' of ' + str(epochs))\n",
    "\n",
    "    for step in range(len(low_res)):\n",
    "      if step % 100 == 0:\n",
    "        print('training image:' + str(step + 1) + ' of ' + str(len(low_res)))\n",
    "          \n",
    "        image = torch.from_numpy(expand(low_res[step]))\n",
    "        original = torch.from_numpy(expand(originals[step]))\n",
    "\n",
    "        image = image.to(device)\n",
    "        original = original.to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "\n",
    "        loss = loss_fn(pred, original)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "  torch.save(model, \"multiresolution-factor\" + str(factor) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(low_res, high_res, originals, model):\n",
    "  for step in range(len(low_res)):\n",
    "    original_image = torch.from_numpy(expand(originals[step])).to(device)\n",
    "    low_res_image = torch.from_numpy(expand(low_res[step])).to(device)\n",
    "    high_res_image = torch.from_numpy(expand(high_res[step])).to(device)\n",
    "\n",
    "    pred = model(low_res_image)\n",
    "\n",
    "    pred = torch.concat([pred, low_res_image[:, 1:3]], axis = 1)\n",
    "\n",
    "    #display_image(pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images_from_folder(TRAIN_FOLDER)\n",
    "\n",
    "display_dataset_info(images, \"DATASET\", 2, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in range(2, 4):\n",
    "  low_res, high_res, originals = preprocess(images, factor, 0)\n",
    "  train(originals, high_res, EPOCHS, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in range(2, 4):\n",
    "  print(\"==========================================================================================\")\n",
    "  print(\"FACTOR: \" + str(factor))\n",
    "  print(\"==========================================================================================\")\n",
    "  model = torch.load(\"multiresolution-factor\" + str(factor) + \".pt\", map_location=device)\n",
    "  print(torchinfo.summary(model, (1, 1, 33, 33)))\n",
    "  display_filters(model.first_conv2d.weight.cpu().detach(), \"FACTOR \" + str(factor) + \" FIRST CONV2D LAYER FILTERS\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in range(2, 4):\n",
    "  model = torch.load(\"multiresolution-factor\" + str(factor) + \".pt\", map_location=device)\n",
    "\n",
    "  for dataset in [ f.path for f in os.scandir(TEST_FOLDER) if f.is_dir() ]:\n",
    "    images = load_images_from_folder(dataset + \"/test/\")\n",
    "\n",
    "    display_dataset_info(images, \"DATASET: \" + dataset.split(\"/\")[1] + \", FACTOR: \" + str(factor), 5, 1, 5)\n",
    "\n",
    "    low_res, high_res, originals = preprocess(images, factor, 1)\n",
    "\n",
    "    test(low_res, high_res, originals, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6532684ccaeb1bcbbe852b7f75c67e6f1d55df7d386020fd37670376cbe3d2c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
